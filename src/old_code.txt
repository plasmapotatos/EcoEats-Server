below is for touch up recipe (before routes were merged)

@app.route("/touchup_recipe", methods=["POST"])
def touchup_recipe():
    global latest_recipe

    if latest_recipe is None:
        return jsonify({"error": "No prior recipe found. Generate a recipe first."}), 400

    preferences = request.json.get("preferences", "")
    print(preferences)
    if not preferences:
        return jsonify({"error": "No preferences provided"}), 400

    original_recipe_str = json.dumps(latest_recipe, indent=2)
    prompt = TOUCHUP_RECIPE_PROMPT.format(
        original_recipe=original_recipe_str,
        preferences=preferences
    )

    response = call_ollama("llama3.2:latest", prompt)
    raw_response = response["message"]["content"]

    # Parse and update the latest_recipe
    updated_recipe = extract_json_from_response(raw_response)
    if updated_recipe is None:
        return jsonify({"error": "Failed to parse updated recipe", "raw_response": raw_response}), 500

    # Update global
    latest_recipe = updated_recipe

    title = updated_recipe.get("title", "Updated Dish")
    ingredients_list = updated_recipe.get("ingredients", [])
    steps_list = updated_recipe.get("steps", [])

    image_prompt = f"A realistic photo of the final dish prepared from this recipe titled '{title}' with the following steps: {' '.join(steps_list)}"
    image = pipe(image_prompt, num_inference_steps=10, guidance_scale=7.5).images[0]
    image.save("generated_dish.jpg")
    image_base64 = pil_to_base64(image)

    return jsonify({
        "title": title,
        "ingredients": ingredients_list,
        "steps": steps_list,
        "image_base64": image_base64
    })

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)

""" TODO: Replace the placeholder image block with a call to API for Stable Diffusion, passing image_prompt. """



below is for generate_recipe

'''  
try:
        ingredients = request.json["ingredients_text"]
        print("ingredients: ", ingredients)

        # Build prompt
        recipe_prompt = GENERATE_RECIPE_PROMPT.format(ingredients=ingredients)
        #print("recipe_prompt: ", recipe_prompt) - debugging

        # Call model
        response = call_ollama("llama3.2:latest", recipe_prompt)
        print("OLLAMA HAS BEEN CALLED!!")
        if "message" not in response or "content" not in response["message"]:
            return jsonify({"error": "Invalid model response"}), 500

        raw_response = response["message"]["content"]
        print("Raw model response:\n", raw_response)

        recipe_json = extract_json_from_response(raw_response)
        if recipe_json is None:
            return jsonify({"error": "Failed to parse recipe JSON", "raw_response": raw_response}), 500

        title = recipe_json.get("title", "Generated Dish")
        ingredients_list = recipe_json.get("ingredients", [])
        steps_list = recipe_json.get("steps", [])

        # Generate image prompt from recipe
        image_prompt = f"A realistic photo of the final dish prepared from this recipe titled '{title}' with the following steps: {' '.join(steps_list)}"
        print("Image prompt:", image_prompt)

        image = pipe(image_prompt, num_inference_steps=10, guidance_scale=7.5).images[0]
        image.save("generated_dish.jpg")
        image_base64 = pil_to_base64(image)

        global latest_recipe
        latest_recipe = {
            "title": title,
            "ingredients": ingredients_list,
            "steps": steps_list
        }

        print("latest_recipe: ", latest_recipe)

        return jsonify({
            "title": title,
            "ingredients": ingredients_list,
            "steps": steps_list,
            "image_base64": image_base64
        })

    except Exception as e:
        return jsonify({"error": f"Failed to generate recipe or image: {str(e)}"}), 500 '''




'''
    try:
        ingredients_text = request.json.get("ingredients_text")
        base64_image = request.json.get("base64_image")

        if not ingredients_text and not base64_image:
            return jsonify({"error": "No ingredient text or image provided."}), 400

        # Choose model based on input type
        model_name = "llava:13b" if base64_image else "llama3.2:latest"

        if base64_image and ingredients_text:
            # Both inputs present — prompt that includes text and image
            prompt = GENERATE_RECIPE_PROMPT.format(
                ingredients=(
                    f"Ingredients text: {ingredients_text}\n"
                    "Please also check the attached image for ingredients. "
                    "Create a proper ingredient list by combining both the image and text. "
                    "(Avoid duplicates as best as possible.)"
                )
            )
            inputs = [base64_image]
        elif base64_image:
            # Only image provided — placeholder text prompt + image input
            prompt = GENERATE_RECIPE_PROMPT.format(
                ingredients="Please check the attached image for ingredients."
            )
            inputs = [base64_image]
        else:
            # Only text provided — no image input
            prompt = GENERATE_RECIPE_PROMPT.format(ingredients=ingredients_text)
            inputs = []

        # Call Ollama with prompt + optional image(s)
        # recipe_response = call_ollama("llama3.2-vision:latest", prompt, inputs)['message']['content']
        response = call_ollama(model_name, prompt, inputs)
        print("Ollama raw response:", response)
        if "error" in response:
            return jsonify({"error": f"Ollama error: {response['error']}"}), 500
        if "message" not in response or "content" not in response["message"]:
            return jsonify(
                {"error": f"Unexpected Ollama response format: {response}"}
            ), 500

        recipe_response = response["message"]["content"]
        print("Generated Recipe:\n", recipe_response)

        # print("Generated Recipe:\n", recipe_response)

        # Generate image prompt and image from recipe text
        image_prompt = f"A realistic photo of the final dish prepared from the following recipe:\n{recipe_response}"
        image = pipe(image_prompt, num_inference_steps=10, guidance_scale=7.5).images[0]

        image.save("generated_dish.jpg")
        image_base64_out = pil_to_base64(image)

        return jsonify(
            {
                "recipe": recipe_response,
                "image_prompt": image_prompt,
                "image_base64": image_base64_out,
            }
        )
    except Exception as e:
        return jsonify({"error": f"Failed to generate recipe or image: {str(e)}"}), 500'''